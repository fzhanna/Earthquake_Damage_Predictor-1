{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will begin the multinomial log-linear models via a neural networks, then LDA and finally QDA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "setwd('C:/Users/iceca/Documents/Earthquake_Damage_Predictor')\n",
    "library(tidyverse)\n",
    "library(MASS)\n",
    "library(caret)\n",
    "library(nnet)\n",
    "library(randomForest)\n",
    "library(e1071)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Joining, by = \"building_id\"\n",
      "Joining, by = \"building_id\"\n"
     ]
    }
   ],
   "source": [
    "loadFin<- modules::use('Helpers/Load_Final_Data.R')\n",
    "train <- loadFin$filtered()[[1]]\n",
    "trainLab <- loadFin$filtered()[[2]]\n",
    "val <- loadFin$filtered()[[3]]\n",
    "valLab <- loadFin$filtered()[[4]]\n",
    "test <- loadFin$filtered()[[5]]\n",
    "\n",
    "#when R reads the csv, it thinks damage_grade is an integer, so convert it back to a factor\n",
    "trainLab$damage_grade <- as.factor(trainLab$damage_grade)\n",
    "valLab$damage_grade <- as.factor(valLab$damage_grade)\n",
    "\n",
    "manipulate<- modules::use('Helpers/Manipulate.R')\n",
    "trainFull <- manipulate$combineLab(train, trainLab)\n",
    "valFull <- manipulate$combineLab(val, valLab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving predictions helper function\n",
    "savePredictions <- function(model) {\n",
    "    preds <- cbind(test$building_id, predict(model, subset(test, select=-c(building_id))))\n",
    "    colnames(preds) <- c(\"building_id\", \"damage_grade\")\n",
    "    write.csv(preds, 'Models/Predictions/Random_Forest.csv', row.names=FALSE)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFull$building_id <- NULL\n",
    "valFull$building_id <- NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# weights:  189 (124 variable)\n",
      "initial  value 257668.526186 \n",
      "iter  10 value 217464.131283\n",
      "iter  20 value 205705.053699\n",
      "iter  30 value 205003.169849\n",
      "iter  40 value 201945.506402\n",
      "iter  50 value 196033.749889\n",
      "iter  60 value 192966.323094\n",
      "iter  70 value 188748.846870\n",
      "iter  80 value 186924.092821\n",
      "iter  90 value 185842.187192\n",
      "iter 100 value 185290.207974\n",
      "iter 110 value 185071.299722\n",
      "iter 120 value 184981.660105\n",
      "iter 130 value 184969.544471\n",
      "final  value 184969.479414 \n",
      "converged\n"
     ]
    }
   ],
   "source": [
    "model.Multinom <- multinom(as.factor(damage_grade) ~ ., trainFull, maxit=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the neural network was  0.5875062"
     ]
    }
   ],
   "source": [
    "prediction <- predict(model.Multinom, valFull)\n",
    "accuracy <- mean(prediction == valFull$damage_grade)\n",
    "cat('Accuracy for the neural network was ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Discriminant Analysis (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the LDA was  0.5797168"
     ]
    }
   ],
   "source": [
    "model.LDA <- lda(as.factor(damage_grade)~., data = trainFull)\n",
    "predictionsVal <- predict(model.LDA, valFull)\n",
    "accuracy <- mean(predictionsVal$class == valFull$damage_grade)\n",
    "cat('Accuracy for the LDA was ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadratic Discriminant Analysis (QDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.426230766279114"
      ],
      "text/latex": [
       "0.426230766279114"
      ],
      "text/markdown": [
       "0.426230766279114"
      ],
      "text/plain": [
       "[1] 0.4262308"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.QDA <- qda(as.factor(damage_grade)~., \n",
    "                 data = trainFull)\n",
    "predictionsVal <- predict(model.QDA, valFull)\n",
    "accuracy <- mean(predictionsVal$class == valFull$damage_grade)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Joining, by = \"building_id\"\n",
      "Joining, by = \"building_id\"\n"
     ]
    }
   ],
   "source": [
    "#Neuralnet preprocessing\n",
    "\n",
    "#one hot encode the label\n",
    "trainLabProcessed <- data.frame(predict(dummyVars(\" ~ .\", data = trainLab), trainLab) )\n",
    "valLabProcessed <- data.frame(predict(dummyVars(\" ~ .\", data = valLab), valLab))\n",
    "\n",
    "#combine test, val, and train to preprocess together\n",
    "ntrain <- nrow(train)\n",
    "nval <- nrow(val)\n",
    "ntest <- nrow(test)\n",
    "X <- rbind(train, val, test)\n",
    "building_id <- X$building_id #extract building_id because it should not be scaled (to assisst in joins)\n",
    "X <- model.matrix(~.-building_id , X)\n",
    "X <- scale(X)\n",
    "X <- data.frame(cbind(X,building_id))\n",
    "X$X.Intercept. <- NULL\n",
    "#trainProcessed <- subset( inner_join(X[1:ntrain,], trainLabProcessed) , select=-c(building_id)) \n",
    "#valProcessed <- subset(inner_join(X[(1:nval) + ntrain ,], valLabProcessed), select=-c(building_id))\n",
    "#testProcessed <- subset(X[(1:ntest) + ntrain + nval,], select=-c(building_id))\n",
    "trainProcessed <- subset(X[1:ntrain,], select=-c(building_id))\n",
    "valProcessed <- subset(X[(1:nval) + ntrain ,], select=-c(building_id))\n",
    "testProcessed <- subset(X[(1:ntest) + ntrain + nval,], select=-c(building_id))\n",
    "trainLab <- subset(trainLab, select=-c(building_id))\n",
    "valLab <- subset(valLab, select=-c(building_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in .doLoadActions(where, attach): error in load action .__A__.1 for package ANN2: Rcpp::loadModule(module = \"ANN\", what = TRUE, env = ns, loadNow = TRUE): Unable to load module \"ANN\": cannot allocate vector of size 12.3 Gb\n",
     "output_type": "error",
     "traceback": [
      "Error in .doLoadActions(where, attach): error in load action .__A__.1 for package ANN2: Rcpp::loadModule(module = \"ANN\", what = TRUE, env = ns, loadNow = TRUE): Unable to load module \"ANN\": cannot allocate vector of size 12.3 Gb\nTraceback:\n",
      "1. ANN2::neuralnetwork",
      "2. getExportedValue(pkg, name)",
      "3. asNamespace(ns)",
      "4. getNamespace(ns)",
      "5. loadNamespace(name)",
      "6. methods::cacheMetaData(ns, TRUE, ns)",
      "7. .doLoadActions(where, attach)",
      "8. stop(gettextf(\"error in load action %s for package %s: %s: %s\", \n .     aname, getPackageName(where), callString, value$message))"
     ]
    }
   ],
   "source": [
    " model.Neuralnet <- ANN2::neuralnetwork(trainProcessed, trainLab, lossFunction = \"log\",\n",
    "  rectifierLayers = NA, sigmoidLayers = NA, regression = FALSE,\n",
    "  standardize = TRUE, learnRate = 5e-03, maxEpochs = 10,\n",
    "  hiddenLayers = c(5, 5), momentum = 0.9, learnRate = 0.001, verbose = TRUE)\n",
    "\n",
    "#f = as.formula(\"damage_grade.1 + damage_grade.2 + damage_grade.3 ~. -building_id\")\n",
    "#nn <- neuralnet(f,\n",
    "#                data = trainProcessed,\n",
    "#                hidden = c(5, 5, 5), threshold = 0.001,\n",
    "#                act.fct = \"tanh\",\n",
    "#                linear.output = FALSE,\n",
    "#                lifesign = \"minimal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtry <- c(5,10,15,20,25)\n",
    "ntree <- c(80,70,60,50,40) \n",
    "\n",
    "createRandomForest <- function(mtry_, ntree_, trainFull, valFull){\n",
    "    model.RF <- randomForest(as.factor(damage_grade) ~ ., data=trainFull, ntree=ntree_, mtry=mtry_, importance=TRUE)\n",
    "    #dput(list(model.RF$confusion, modelRF$oob.times, modelRF$, \"Models/Random_Forest_Output.txt\")\n",
    "    cat('RESULTS FOR RANDOM FOREST, with mtry=', mtry_, 'ntree=', ntree_, '\\n \\n')\n",
    "    \n",
    "    predictionsVal <- predict(model.RF, valFull)\n",
    "    accuracy <- mean(predictionsVal == valFull$damage_grade)\n",
    "    cat('The accuracy for this random forest was',accuracy, '\\n')\n",
    "    \n",
    "    cat('\\n Confusion Matrix \\n')\n",
    "    print(model.RF$confusion)\n",
    "    \n",
    "    cat('\\n Variables sorted in importance (decreasing)\\n')\n",
    "    imp <- as.data.frame(importance(model.RF))\n",
    "    print(subset ( imp[order(-imp$MeanDecreaseGini),] ,select=MeanDecreaseGini))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "createRandomForest(mtry[1],ntree[1], trainFull, valFull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "createRandomForest(mtry[2],ntree[2], trainFull, valFull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "createRandomForest(mtry[3],ntree[3], trainFull, valFull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "createRandomForest(mtry[4],ntree[4], trainFull, valFull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "createRandomForest(mtry[5],ntree[5], trainFull, valFull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best model based on accuracy of the previous models\n",
    "model.RF <- randomForest(as.factor(damage_grade) ~ ., data=rbind(trainFull,valFull), ntree=ntree[1], mtry=mtry[1], importance=FALSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "savePredictions(model.RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "createSVMModel <- function(kernel, cost, trainFull, valFull, gamma=0.1, degree=1) {\n",
    "    if (kernel == \"linear\"){\n",
    "        cat(\"Kernel selected as linear\")\n",
    "        model.SVM <- svm(as.factor(damage_grade) ~., data=trainFull, cost=cost, scale=TRUE, kernel=\"linear\")\n",
    "    }\n",
    "    if (kernel == \"polynomial\") {\n",
    "        cat(\"Kernel selected as polynomial\")\n",
    "        model.SVM  <- svm(as.factor(damage_grade) ~., data=trainFull, cost=cost, degree=degree, scale=TRUE, kernel=\"polynomial\")\n",
    "    }\n",
    "    if (kernel == \"radial\") {\n",
    "        cat(\"Kernel selected as radial\")\n",
    "        model.SVM <- svm(as.factor(damage_grade) ~., data=trainFull, cost=cost,gamma=gamma, scale=TRUE, kernel=\"radial\")\n",
    "    }\n",
    "    preds <- predict(model.SVM, valFull)\n",
    "    acc <- mean(preds == valFull$damage_grade)\n",
    "    cat('The accuracy for this SVM, with kernel', kernel, 'and cost', cost,'\\n\\n')\n",
    "}\n",
    "gammaSearch <- 10^(-9:3)\n",
    "costSearch <- 10^(-3:3)\n",
    "degreeSearch <- 1:5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(parallelSVM)\n",
    "model.SVM <- parallelSVM(as.factor(damage_grade) ~., data=trainFull, sampleSize=0.1,kernel=\"linear\", cost=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for this SVM, with kernel linear and cost 0.5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds <- predict(model.SVM, valFull)\n",
    "acc <- mean(preds == valFull$damage_grade)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for this SVM, with kernel linear and cost 0.5 was 0.5717739 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat('The accuracy for this SVM, with kernel','linear', 'and cost', 0.5,'was',acc,'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear search\n",
    "for (c in c(0.01, 1, 10)){ \n",
    "    createSVMModel(\"linear\", c, trainFull, valFull) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#polynomial\n",
    "polyParams <- expand.grid(costSearch, degreeSearch)\n",
    "ntry <- 10\n",
    "set.seed(5)\n",
    "params <- sample(1:nrow(polyParams) , ntry, replace=FALSE)\n",
    "for (i in params){\n",
    "    c <- polyParams[i,]$cost\n",
    "    deg <- polyParams[i,]$degree\n",
    "    cat('PARAMETERS: COST',c,' DEGREE ',deg, '\\n')\n",
    "    createSVMModel(\"polynomial\", c, trainFull, valFull, degree=deg) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#radial\n",
    "radParams <- expand.grid(cost=costSearch, gamme=gammaSearch)\n",
    "ntry <- 10\n",
    "set.seed(5)\n",
    "params <- sample(1:nrow(radParams) , ntry, replace=FALSE)\n",
    "for (i in params){\n",
    "    c <- radParams[i,]$cost\n",
    "    gam <- radParams[i,]$gamma\n",
    "    createSVMModel(\"polynomial\", c, trainFull, valFull, gamma=gam) \n",
    "    cat('PARAMETERS: COST',c,' GAMMA ',gam, '\\n')\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
